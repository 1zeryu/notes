# 主成分分析

## 相关背景

### 数据分析的难题

​	在研究实际的许多复杂问题时，经常需要对多个变量（特征）的数据进行观测，多变量的大数据会给研究和应用提供丰富的信息，但也同时增加了数据采集的工作量，并且在多数情况下，我们研究对象的特征是相互作用和影响的，例如身高和体重，这些都在一定程度上会增加问题分析的复杂度

​	如果分别对每个指标进行孤立分析时，我们可以减少某些数据来减少复杂度，但由于分析是孤立的，不能提现数据之间的相互作用，因此盲目减少指标会损失很多有用的信息

### 解决方法

​	我们需要找到一种合理的方法，在减少指标的同时，尽量减少原指标包含的信息损失，以达到对所收集的数据做到全面分析的目的，所以要达到一下几点

* 由于各变量的相互关系，可以考虑将关系密集的变量变成尽可能少的新变量，使新变量是不相关的
* 可以用较少的综合指标分别表示存在各个变量的各类信息

主成分分析和因子分析就是这类的降维算法

## 数据降维

​	降维就是一种对高纬度特征数据预处理方法，降维是将高纬度数据保留下最重要的特征，去除噪点和不重要的特征，从而实现提高数据处理书读的目的，降维是广泛应用的数据预处理方法

具有一下优点：

* 使数据更容易使用
* 降低算法的开销
* 去除噪点
* 使结果容易理解

算法：SVD，PCA，FA(因子分解)，独立成分分析

## PCA原理

### 概念

PCA（principal component analysis），主成分分析，主要思想是将原n维数据，找到这些特征相互作用下重要的k个方向，然后将n维数据映射到k维数据上，那么怎么找这k个方向呢，我们定义在这k个方向最能提现数据的特征，那么可以定义在这k个方向上方差最大时，是我们要找的方向

* 映射到k个方向上后，方差最大，表示数据之间的差异最能体现，相互之间的独立特征最明显，试想，如果所有数据都映射成一个点的话，能体现数据之间的特征吗
* k个方向是互相正交的，因为我们要找到的新特征必须相互之间不影响

思考：如何找到最大差异性的主成分方向?

答案：对协方差矩阵进行特征值分解或奇异值分解

### PCA算法两种实现方法

* **基于特征值分解协方差矩阵实现PCA算法**

输入：数据集$X = {x_1,x_2,..,x_n}$需要降至k维

1. 去平均值（去中心化），即每一位特征减去各自的平均值
2. 计算协方差矩阵$\frac 1 n XX^T$,注：这里出除去样本数量n或n-1，其实对求出的特征向量没有影响
3. 用特征值分解方法求协方差矩阵$\frac 1 n XX^T$的特征值和特征向量
4. 对特征值从大到小排序，选择其中最大的k个，然后将其对应的k个特征向量分别作为行向量组成特征向量矩阵P
5. 将数据转换到k个特征向量构建的新空间中，即Y=PX









* 基于SVD分解协方差矩阵实现PCA算法

输入：数据集$X={x_1,x_2,...,x_n}$，需要降至k维

1. 去平均值
2. 计算协方差矩阵
3. 通过SVD计算协方差矩的特征值与特征向量
4. 对特征值从小到大排序，选择最大的k个，然后其对应的k个特征向量分别作为列向量组成特征向量P
5. 将数据转化到k个特征向量构建的新空间中，即Y=PX